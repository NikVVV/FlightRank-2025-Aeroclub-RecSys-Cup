{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc47a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1tiii\\AppData\\Local\\Temp\\ipykernel_23220\\103309096.py:22: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  .collect(streaming=True)    # constant-memory execution\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import datetime\n",
    "from polars.datatypes import (\n",
    "    Boolean, UInt8, UInt16, UInt32, UInt64, Utf8,\n",
    "    Int8, Int16, Int32, Int64,\n",
    "    Float32, Float64\n",
    ")\n",
    "from polars.datatypes import Utf8, Datetime, Date, Time\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import ndcg_score\n",
    "from geopy.distance import geodesic\n",
    "from src.utils.utils import evaluate_feature\n",
    "from src.train_new_base import train_base_model\n",
    "rows = (\n",
    "    pl.scan_parquet(\"data/train.parquet\")        # or scan_parquet/scan_ndjson/‚Ä¶\n",
    "      .select(pl.len())           # len() == COUNT(*)\n",
    "      .collect(streaming=True)    # constant-memory execution\n",
    "      .item()                     # get the scalar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7f28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\"data/clean_data_cut.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c958277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['company_count', 'company_freq', 'totalPrice', 'route_distance_km', 'frequentFlyer_n_programs', 'unique_ranker_count', 'hour_sin', \n",
    "                'hour_cos', 'wday_sin', 'wday_cos', 'twoway_route', 'avg_oneway_price', 'total_duration_hours_leg0', 'total_duration_hours_leg1', 'legs0_segments0_aircraft_code_freq',\n",
    "                'legs1_segments0_aircraft_code_freq', 'frequentFlyer', 'isVip', 'miniRules0_monetaryAmount', 'miniRules0_percentage',\n",
    "                'miniRules1_monetaryAmount', 'miniRules1_percentage', 'sex', 'total_segments_count', 'legs0_num_segments', 'legs1_num_segments', 'tariff_code_filled', 'nationality_cat', 'miniRules0_statusInfos',\n",
    "                'miniRules1_statusInfos', 'pricingInfo_isAccessTP', 'legs0_departureAt_period', 'legs0_arrivalAt_period', 'legs1_departureAt_period', 'legs1_arrivalAt_period',\n",
    "                'legs0_segments0_baggageAllowance_quantity_kg', 'legs1_segments0_baggageAllowance_quantity_kg', 'legs0_segments0_cabinClass_cat', 'legs1_segments0_cabinClass_cat']\n",
    "FEATURE_COLUMNS_V1 = [\n",
    "    # 1-2. –ü–µ—Ä–µ—Å–∞–¥–∫–∏\n",
    "    \"layover_hours_leg0\",\n",
    "    \"layover_hours_leg1\",\n",
    "\n",
    "    # 3. –°–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –¥–æ –≤—ã–ª—ë—Ç–∞\n",
    "    \"days_before_flight_leg0\",\n",
    "\n",
    "    # 4 + 6. –°–º–µ–Ω–∞ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞ –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–π –Ω–æ–≥–∏\n",
    "    \"legs0_airport_changes_count\",\n",
    "    \"legs1_airport_changes_count\",\n",
    "\n",
    "    # 5. –ù–æ—á–Ω–∞—è –ø–µ—Ä–µ—Å–∞–¥–∫–∞\n",
    "    \"night_layover_leg0\",\n",
    "    \"night_layover_leg1\",\n",
    "\n",
    "    # 7 + 11. –û–¥–Ω–∞ –ª–∏ –∞–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è-–æ–ø–µ—Ä–∞—Ç–æ—Ä\n",
    "    \"same_operator_carrier_leg0\",\n",
    "    \"same_operator_carrier_leg1\",\n",
    "\n",
    "    # 8. –£—á–∞—Å—Ç–∏–µ –±–∏–ª–µ—Ç–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏\n",
    "    \"ticket_is_in_FFprogramms_leg0\",\n",
    "    \"ticket_is_in_FFprogramms_leg1\",\n",
    "\n",
    "    # 9. –†–∞–Ω–≥ –ø–æ —Ü–µ–Ω–µ\n",
    "    \"totalPrice_rank\",\n",
    "\n",
    "    # 10. –†–∞–Ω–≥ –ø–æ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏ –ø–µ—Ä–µ–ª—ë—Ç–∞\n",
    "    \"totalTime_hours_ranked\",\n",
    "\n",
    "    # 12. –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –±–∞–≥–∞–∂–∞\n",
    "    \"baggage_kg_equal_flag\",\n",
    "    \"baggage_units_equal_flag\",\n",
    "\n",
    "    # 13. –°–∫–æ–ª—å–∫–æ –±–∏–ª–µ—Ç–æ–≤ –ø–æ–∫–∞–∑–∞–Ω–æ –≤ –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–µ—Å—Å–∏–∏\n",
    "    \"tickets_in_session\",\n",
    "\n",
    "    # 14. –ú–µ—Ç—Ä–∏–∫–∏ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –±–∏–ª–µ—Ç–æ–≤\n",
    "    \"remainingTickets_avg\",\n",
    "    \"remainingTickets_rank\",\n",
    "\n",
    "    # 15. –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ–∫—É–ø–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    \"user_search_freq\",\n",
    "\n",
    "    # 16. –î–æ–ª—è —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä-–ø—Ä–æ–¥–∞–≤–µ—Ü\n",
    "    \"operator_marketer_match_rate\",\n",
    "\n",
    "    # 17. –ë–∏–ª–µ—Ç ‚â§ 20 % –¥–æ—Ä–æ–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ\n",
    "    \"within_20pct_of_min\",\n",
    "\n",
    "    # 18. –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –≤—ã–ª–µ—Ç–∞ (—Å–∏–Ω—É—Å/–∫–æ—Å–∏–Ω—É—Å)\n",
    "    \"leg0_depday_sin\", \"leg1_depday_sin\",\n",
    "    \"leg0_depday_cos\", \"leg1_depday_cos\",\n",
    "\n",
    "    # 19. –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –ø—Ä–∏–ª—ë—Ç–∞ (—Å–∏–Ω—É—Å/–∫–æ—Å–∏–Ω—É—Å)\n",
    "    \"leg0_arrday_sin\", \"leg1_arrday_sin\",\n",
    "    \"leg0_arrday_cos\", \"leg1_arrday_cos\",\n",
    "\n",
    "    # 20. –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è ¬´–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—Å—Ç—å¬ª –±–∏–ª–µ—Ç–∞\n",
    "    \"opt_ticket_score\",\n",
    "]\n",
    "FEATURE_COLUMNS_V2 = [\n",
    "    # C—á—ë—Ç—á–∏–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
    "    \"n_segments_leg0\",\n",
    "    \"n_segments_leg1\",\n",
    "    \"is_one_way\",\n",
    "    \"total_segments\",\n",
    "    \"is_direct_leg0\",\n",
    "    \"is_direct_leg1\",\n",
    "    \"both_direct\",\n",
    "\n",
    "    # –°—Ç–æ–∏–º–æ—Å—Ç—å, –Ω–∞–ª–æ–≥–∏, —Å–±–æ—Ä—ã\n",
    "    \"price_per_tax\",\n",
    "    \"tax_rate\",\n",
    "    \"log_price\",\n",
    "    \"total_fees\",\n",
    "    \"has_fees\",\n",
    "    \"fee_rate\",\n",
    "\n",
    "    # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    \"duration_ratio\",\n",
    "\n",
    "    # –¢–∞—Ä–∏—Ñ—ã –∏ –ø—Ä–∏–≤–∏–ª–µ–≥–∏–∏\n",
    "    \"has_corporate_tariff\",\n",
    "    \"has_access_tp\",\n",
    "    \"n_ff_programs\",\n",
    "    \"is_vip_freq\",\n",
    "\n",
    "    # –ö–ª–∞—Å—Å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è\n",
    "    \"avg_cabin_class\",\n",
    "    \"cabin_class_diff\",\n",
    "\n",
    "    # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã\n",
    "    \"is_popular_route\",\n",
    "\n",
    "    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ü–µ–Ω—ã –∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –ø–æ–∏—Å–∫–∞\n",
    "    \"price_pct_rank\",\n",
    "    \"is_cheapest\",\n",
    "    \"price_from_median\",\n",
    "    \"is_min_segments\",\n",
    "    \"is_direct_cheapest\",\n",
    "]\n",
    "feature_list = feature_cols + FEATURE_COLUMNS_V1 + FEATURE_COLUMNS_V2\n",
    "cat_features_final = ['tariff_code_filled', 'nationality_cat', 'legs0_departureAt_period', 'legs0_arrivalAt_period',\n",
    "                      'legs1_departureAt_period', 'legs1_arrivalAt_period', 'legs0_segments0_cabinClass_cat', 'legs1_segments0_cabinClass_cat', 'frequentFlyer']\n",
    "#feature_cols = ['totalPrice']\n",
    "#cat_features_final = []\n",
    "#X = data.select(feature_cols)\n",
    "#y = data.select(\"selected\")            # Polars DataFrame with 1 col\n",
    "#groups = data.select(\"ranker_id\")      # Polars DataFrame with 1 col\n",
    "n2 = rows\n",
    "\n",
    "# 5. Set params to use pairwise ranking + ndcg@3 + histogram tree builder\n",
    "params = {\n",
    "    \"objective\":   \"rank:pairwise\",\n",
    "    \"eval_metric\": \"ndcg@3\",\n",
    "    \"tree_method\": \"hist\",      # üî• much faster\n",
    "    \"seed\":        42,\n",
    "    \"n_jobs\":      -1,\n",
    "    'eta': 0.14381590394747168,\n",
    "    \"learning_rate\": 0.022641389657079056,\n",
    "    'max_depth': 14,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': 0.7308722227055789,\n",
    "    \"colsample_bytree\": 0.45840689146263086,\n",
    "    \"gamma\": 3.3084297630544888,\n",
    "    \"lambda\": 6.952586917313028,\n",
    "    \"alpha\": 0.6395254133055179,\n",
    "    'num_boost_round': 1500\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e5676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean top@3 -  0.4192\n",
      "std top@3 -  0.0027\n",
      "mean ndcg@3 -  0.3848\n",
      "std ndcg@3 -  0.002\n"
     ]
    }
   ],
   "source": [
    "cv_stats = pd.read_csv('model/cv_results.csv')\n",
    "print('mean top@3 - ', round(cv_stats['val-top@3'].mean(), 4))\n",
    "print('std top@3 - ', round(cv_stats['val-top@3'].std(), 4))\n",
    "print('mean ndcg@3 - ', round(cv_stats['val-ndcg@3'].mean(), 4))\n",
    "print('std ndcg@3 - ', round(cv_stats['val-ndcg@3'].std(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39834948",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['totalPrice', 'ranker_id', 'selected', 'company_count', 'route_distance_km', 'frequentFlyer_n_programs', 'unique_ranker_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d078ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top@3 before -  0.2258  top@3 after -  0.2237\n",
      "ndcg@3 before -  0.2622  top@3 after -  0.2614\n",
      "mean top@3 -  0.2239\n",
      "std top@3 -  0.003\n",
      "mean ndcg@3 -  0.2621\n",
      "std ndcg@3 -  0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'corr': np.float64(0.005832222368000487),\n",
       " 'warm_delta': np.float64(-0.0021618937392779147),\n",
       " 'mini_delta': None}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sigma = np.std(pd.read_csv('model/cv_results.csv')['val-top@3']), np.mean(pd.read_csv('model/cv_results.csv')['val-top@3'])\n",
    "meta, df = evaluate_feature(data[:n2][feature_list], \n",
    "                       new_feature_name='unique_ranker_count', \n",
    "                       group_col='ranker_id', \n",
    "                       label_col='selected', \n",
    "                       baseline_model='model/base.json', \n",
    "                       params=params, \n",
    "                       sigma0=top_sigma[1],\n",
    "                       corr_threshold=0.00,\n",
    "                       cat_features_final=cat_features_final)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "320ea251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted by ncdg3\n"
     ]
    }
   ],
   "source": [
    "if round(cv_stats['val-top@3'].mean(), 4) < round(df['val-top@3'].mean(), 4):\n",
    "    print('accepted by top@3')\n",
    "if round(cv_stats['val-ndcg@3'].mean(), 4)  < round(df['val-ndcg@3'].mean(), 4):\n",
    "    print('accepted by ncdg3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcf71f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pandas().to_csv('model/cv_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:14:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4694783687591553\n"
     ]
    }
   ],
   "source": [
    "res = train_base_model(data=data[:n2], \n",
    "                 features=feature_list, \n",
    "                 label_col='selected', \n",
    "                 group_col='ranker_id', \n",
    "                 params=params, \n",
    "                 num_boost_round=1000, \n",
    "                 baseline_model_path='model/', \n",
    "                 seed=42, \n",
    "                 verbose_eval_size=5, \n",
    "                 full_cv = False,\n",
    "                 cat_features_final=cat_features_final)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66981d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.Booster()\n",
    "booster.load_model('model/base.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d4c0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_sizes(ranker_ids: np.ndarray) -> np.ndarray:\n",
    "    # unique in order of first appearance + their counts\n",
    "    uniq, idx, counts = np.unique(ranker_ids, return_index=True, return_counts=True)\n",
    "    return counts[np.argsort(idx)]\n",
    "data_xgb = data[n2:].with_columns([\n",
    "                                (pl.col(c).rank(\"dense\") - 1)\n",
    "                                .fill_null(-1)\n",
    "                                .cast(pl.Int32)\n",
    "                                .alias(c)\n",
    "                                for c in cat_features_final\n",
    "                            ])\n",
    "label_col = 'selected'\n",
    "group_col = 'ranker_id'\n",
    "feature_cols_all = feature_list\n",
    "data_test = xgb.DMatrix(data_xgb.select(feature_cols_all).to_numpy(), feature_names=feature_cols_all, group=get_group_sizes(data_xgb.select(group_col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e454f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = booster.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb35eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pl.read_parquet('data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7904efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb = (\n",
    "    test.select(['Id', 'ranker_id'])\n",
    "    .with_columns(pl.Series('pred_score', preds))\n",
    "    .with_columns(\n",
    "        pl.col('pred_score')\n",
    "        .rank(method='ordinal', descending=True)\n",
    "        .over('ranker_id')\n",
    "        .cast(pl.Int32)\n",
    "        .alias('selected')\n",
    "    )\n",
    "    .select(['Id', 'ranker_id', 'selected', 'pred_score'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07963157",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb.write_csv('submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a28bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "LABEL_COL = \"selected\"          # binary 1/0 ‚Äì chosen by the user\n",
    "GROUP_COL = \"ranker_id\"         # search/session id\n",
    "FEATURE_COLUMNS = feature_list\n",
    "CAT_FEATURES_FINAL = cat_features_final\n",
    "def get_group_sizes(ranker_ids: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return group‚Äêsizes array for XGBoost ranking.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ranker_ids : np.ndarray\n",
    "        1‚ÄëD array with group id (ranker_id) of every row in the same order as X.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of group sizes, ordered by the first appearance of each id (exactly\n",
    "        what xgb.DMatrix wants for ranking).\n",
    "    \"\"\"\n",
    "    uniq, idx, counts = np.unique(ranker_ids, return_index=True, return_counts=True)\n",
    "    return counts[np.argsort(idx)]\n",
    "def train_single_split(\n",
    "    data_xgb: pl.DataFrame,\n",
    "    params: dict,\n",
    "    num_boost_round: int,\n",
    "    seed: int = 42,\n",
    ") -> float:\n",
    "    \"\"\"Train XGBoost on a random 80/20 group‚Äëbased split and return hit@3.\"\"\"\n",
    "\n",
    "    # Ordinal‚Äëencode categorical features ------------------------------------------------\n",
    "\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    groups_unique = data_xgb.select(GROUP_COL).unique().to_numpy().ravel()\n",
    "    val_groups = rng.choice(groups_unique, size=max(1, int(0.2 * len(groups_unique))), replace=False)\n",
    "\n",
    "    val_df = data_xgb.filter(pl.col(GROUP_COL).is_in(val_groups))\n",
    "    train_df = data_xgb.filter(~pl.col(GROUP_COL).is_in(val_groups))\n",
    "\n",
    "    feature_cols = [c for c in FEATURE_COLUMNS if c not in {LABEL_COL, GROUP_COL}]\n",
    "\n",
    "    dtrain = xgb.DMatrix(\n",
    "        train_df.select(feature_cols).to_numpy(),\n",
    "        label=train_df.select(LABEL_COL).to_numpy().ravel(),\n",
    "        group=get_group_sizes(train_df.select(GROUP_COL).to_numpy().ravel()),\n",
    "        feature_names=feature_cols,\n",
    "    )\n",
    "\n",
    "    dval = xgb.DMatrix(\n",
    "        val_df.select(feature_cols).to_numpy(),\n",
    "        label=val_df.select(LABEL_COL).to_numpy().ravel(),\n",
    "        group=get_group_sizes(val_df.select(GROUP_COL).to_numpy().ravel()),\n",
    "        feature_names=feature_cols,\n",
    "    )\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dval, \"val\")],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # NDCG@3 produced by XGBoost is geometric mean across groups; for hit@3 we compute manually\n",
    "    preds = bst.predict(dval)\n",
    "\n",
    "    # Hit@3 ‚Äì at least one correct item in top‚Äë3 per group ------------------\n",
    "    # Reconstruct group slices\n",
    "    ranker_ids = val_df.select(GROUP_COL).to_numpy().ravel()\n",
    "    labels = dval.get_label()\n",
    "    order = np.argsort(ranker_ids, kind=\"stable\")\n",
    "    ranker_ids, labels, preds = ranker_ids[order], labels[order], preds[order]\n",
    "\n",
    "    hit_total, group_total = 0, 0\n",
    "    start = 0\n",
    "    while start < len(ranker_ids):\n",
    "        group = ranker_ids[start]\n",
    "        end = start\n",
    "        while end < len(ranker_ids) and ranker_ids[end] == group:\n",
    "            end += 1\n",
    "        if (end - start) > 10:\n",
    "            group_labels = labels[start:end]\n",
    "            group_preds = preds[start:end]\n",
    "            top3_idx = np.argsort(group_preds)[::-1][:3]\n",
    "            hit_total += int(group_labels[top3_idx].sum() > 0)\n",
    "            group_total += 1\n",
    "        start = end\n",
    "    return hit_total / group_total\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Optuna objective ----------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def objective(trial: optuna.Trial, data: pl.DataFrame) -> float:\n",
    "    params = {\n",
    "        \"objective\": \"rank:pairwise\",\n",
    "        \"eval_metric\": \"ndcg@3\",\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 10.0, log=True),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"single_precision_histogram\": True,\n",
    "        \"max_bin\": 128,\n",
    "        \"seed\": 42,\n",
    "        'device': 'cuda'\n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 300, 1500, step=100)\n",
    "    data_xgb = data.with_columns([\n",
    "    (pl.col(c).rank(\"dense\") - 1)  # rank starts at 1 ‚Üí shift to 0\n",
    "    .fill_null(-1)\n",
    "    .cast(pl.Int32)\n",
    "    .alias(c)\n",
    "    for c in CAT_FEATURES_FINAL\n",
    "    ])\n",
    "    hit_at_3 = train_single_split(\n",
    "        data_xgb=data_xgb,\n",
    "        params=params,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    return hit_at_3  # maximise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73cec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:31:00,571] A new study created in memory with name: no-name-ca9840d4-f07f-47cf-bc7a-bff5524b0287\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:31:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 0. Best value: 0.35665:   2%|‚ñè         | 1/50 [01:58<1:36:35, 118.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:32:58,824] Trial 0 finished with value: 0.3566495878814881 and parameters: {'eta': 0.016799433682372827, 'max_depth': 5, 'min_child_weight': 20, 'subsample': 0.9614366002961072, 'colsample_bytree': 0.7213201036469383, 'gamma': 1.7137185245609894, 'lambda': 6.041193036497697e-07, 'alpha': 0.00901802221641974, 'num_boost_round': 1500}. Best is trial 0 with value: 0.3566495878814881.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:33:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:   4%|‚ñç         | 2/50 [03:24<1:19:30, 99.39s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:34:24,991] Trial 1 finished with value: 0.42007704762436493 and parameters: {'eta': 0.08870660003385719, 'max_depth': 7, 'min_child_weight': 17, 'subsample': 0.6373344331189786, 'colsample_bytree': 0.9551034843619213, 'gamma': 1.321789700331823, 'lambda': 1.9735635430171912e-07, 'alpha': 1.868435583931355, 'num_boost_round': 600}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:34:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:   6%|‚ñå         | 3/50 [04:42<1:10:08, 89.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:35:42,821] Trial 2 finished with value: 0.38929765886287626 and parameters: {'eta': 0.279992293813335, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.8329077229633369, 'colsample_bytree': 0.9755969990496046, 'gamma': 4.028052183805037, 'lambda': 0.0022659354869553608, 'alpha': 2.484745077423099e-06, 'num_boost_round': 600}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:35:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:   8%|‚ñä         | 4/50 [04:55<45:30, 59.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:35:55,907] Trial 3 finished with value: 0.3230366783547615 and parameters: {'eta': 0.019613388631192816, 'max_depth': 3, 'min_child_weight': 13, 'subsample': 0.6283157514185657, 'colsample_bytree': 0.9749313229151269, 'gamma': 1.7926576767561364, 'lambda': 0.0004645264473988765, 'alpha': 0.0013261274951899466, 'num_boost_round': 800}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:36:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  10%|‚ñà         | 5/50 [06:03<46:55, 62.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:37:04,139] Trial 4 finished with value: 0.38335834583958645 and parameters: {'eta': 0.07759584290394192, 'max_depth': 5, 'min_child_weight': 13, 'subsample': 0.613231870575633, 'colsample_bytree': 0.7834919228219692, 'gamma': 0.5292424251646599, 'lambda': 2.20853621773693e-05, 'alpha': 5.233631405198676e-07, 'num_boost_round': 900}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:37:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  12%|‚ñà‚ñè        | 6/50 [06:17<33:42, 45.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:37:17,904] Trial 5 finished with value: 0.33837566285235837 and parameters: {'eta': 0.018692502341774456, 'max_depth': 4, 'min_child_weight': 13, 'subsample': 0.882777588658926, 'colsample_bytree': 0.7931523649436593, 'gamma': 1.2666357708789022, 'lambda': 0.001087182027942776, 'alpha': 0.00021539394147242086, 'num_boost_round': 1100}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:37:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  14%|‚ñà‚ñç        | 7/50 [08:00<46:15, 64.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:39:00,718] Trial 6 finished with value: 0.3791242419184332 and parameters: {'eta': 0.049109061777369165, 'max_depth': 5, 'min_child_weight': 20, 'subsample': 0.8372603618462015, 'colsample_bytree': 0.7296440584886602, 'gamma': 2.801850963046772, 'lambda': 8.196257040742894e-08, 'alpha': 0.0020984229363452235, 'num_boost_round': 1000}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:39:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  16%|‚ñà‚ñå        | 8/50 [08:58<43:50, 62.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:39:59,257] Trial 7 finished with value: 0.38486971140375453 and parameters: {'eta': 0.1732801296789772, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.7402426770728454, 'colsample_bytree': 0.9292892535882693, 'gamma': 0.3818279685768533, 'lambda': 0.30360461534911104, 'alpha': 1.5397847978721687e-05, 'num_boost_round': 800}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:40:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  18%|‚ñà‚ñä        | 9/50 [10:46<52:30, 76.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:41:47,344] Trial 8 finished with value: 0.3970653871903593 and parameters: {'eta': 0.12814813040209747, 'max_depth': 5, 'min_child_weight': 12, 'subsample': 0.9729651257124419, 'colsample_bytree': 0.7754946738282393, 'gamma': 2.5076427575152755, 'lambda': 0.00019214359854910734, 'alpha': 4.0718966672602004e-05, 'num_boost_round': 800}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:41:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  20%|‚ñà‚ñà        | 10/50 [12:00<50:34, 75.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:43:00,984] Trial 9 finished with value: 0.41838555022856505 and parameters: {'eta': 0.2030763743146656, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9129843985466237, 'colsample_bytree': 0.8340645830062385, 'gamma': 2.669174423631815, 'lambda': 0.00011539863330105868, 'alpha': 6.142685196289024e-05, 'num_boost_round': 600}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:43:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  22%|‚ñà‚ñà‚ñè       | 11/50 [12:48<43:49, 67.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:43:49,259] Trial 10 finished with value: 0.3941446484549933 and parameters: {'eta': 0.04027692450272782, 'max_depth': 8, 'min_child_weight': 17, 'subsample': 0.713966511598936, 'colsample_bytree': 0.8819154098667217, 'gamma': 4.848215831054434, 'lambda': 1.658773793482456e-08, 'alpha': 4.595545946375133, 'num_boost_round': 300}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:43:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 1. Best value: 0.420077:  24%|‚ñà‚ñà‚ñç       | 12/50 [13:48<41:11, 65.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:44:48,904] Trial 11 finished with value: 0.4056057060069096 and parameters: {'eta': 0.10989727842322797, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.9050533185793992, 'colsample_bytree': 0.6041077421307431, 'gamma': 3.2336837689589473, 'lambda': 3.2372777797230518e-06, 'alpha': 9.350888229440912, 'num_boost_round': 400}. Best is trial 1 with value: 0.42007704762436493.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:44:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 12. Best value: 0.424018:  26%|‚ñà‚ñà‚ñå       | 13/50 [14:55<40:30, 65.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:45:56,094] Trial 12 finished with value: 0.42401824452108133 and parameters: {'eta': 0.26719262721796244, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7293171122808932, 'colsample_bytree': 0.8680306488294656, 'gamma': 3.414701970831686, 'lambda': 0.17194469533114948, 'alpha': 2.109701442545636e-08, 'num_boost_round': 500}. Best is trial 12 with value: 0.42401824452108133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:46:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  28%|‚ñà‚ñà‚ñä       | 14/50 [16:07<40:35, 67.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:47:08,268] Trial 13 finished with value: 0.43283331467592073 and parameters: {'eta': 0.2887408193928653, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.6897831242711121, 'colsample_bytree': 0.8927024009906425, 'gamma': 3.5828756631243586, 'lambda': 8.901198548020144, 'alpha': 0.16135884133456024, 'num_boost_round': 500}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:47:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  30%|‚ñà‚ñà‚ñà       | 15/50 [16:49<34:57, 59.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:47:50,249] Trial 14 finished with value: 0.4164438502673797 and parameters: {'eta': 0.2749183483793218, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.7294063716982953, 'colsample_bytree': 0.8900946952899895, 'gamma': 3.7718976495652634, 'lambda': 5.459975882670884, 'alpha': 0.08339006219704657, 'num_boost_round': 400}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [18:25<40:05, 70.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:49:26,148] Trial 15 finished with value: 0.41049692908989394 and parameters: {'eta': 0.17215737611440313, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6945674534458719, 'colsample_bytree': 0.8632886641996118, 'gamma': 4.847343385947882, 'lambda': 0.06435647592950272, 'alpha': 1.667763292915514e-08, 'num_boost_round': 1200}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [19:33<38:27, 69.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:50:34,163] Trial 16 finished with value: 0.4073620315197416 and parameters: {'eta': 0.2831365852666034, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.781873369468132, 'colsample_bytree': 0.9030966811901286, 'gamma': 3.969223140237168, 'lambda': 5.382382603513352, 'alpha': 1.602589981715294e-08, 'num_boost_round': 500}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [20:22<33:56, 63.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:51:23,161] Trial 17 finished with value: 0.39802024495274313 and parameters: {'eta': 0.038072451486822076, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.6694924769197279, 'colsample_bytree': 0.9992620176787986, 'gamma': 3.313915606151014, 'lambda': 0.06131124628633514, 'alpha': 0.05893150885720593, 'num_boost_round': 300}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:51:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [22:37<43:56, 85.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:53:38,099] Trial 18 finished with value: 0.39778634915311084 and parameters: {'eta': 0.026668051242005195, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.7704129807607896, 'colsample_bytree': 0.8407037699240886, 'gamma': 4.367402093998503, 'lambda': 0.5338144244439076, 'alpha': 0.3675316796862543, 'num_boost_round': 1300}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:53:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [22:57<32:40, 65.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:53:57,551] Trial 19 finished with value: 0.3559624832514515 and parameters: {'eta': 0.012189762885118336, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.6673017029150318, 'colsample_bytree': 0.6411714391433039, 'gamma': 3.2937287668918898, 'lambda': 0.010581272298300887, 'alpha': 4.467541778296972e-07, 'num_boost_round': 700}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:54:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [24:10<32:42, 67.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:55:10,614] Trial 20 finished with value: 0.40661120107208665 and parameters: {'eta': 0.06708686890458095, 'max_depth': 7, 'min_child_weight': 11, 'subsample': 0.8108767769864405, 'colsample_bytree': 0.9308671781226242, 'gamma': 2.099051916994381, 'lambda': 0.7882444156311661, 'alpha': 0.014615470432388703, 'num_boost_round': 500}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:55:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 13. Best value: 0.432833:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [25:35<34:06, 73.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:56:36,340] Trial 21 finished with value: 0.4169120506694816 and parameters: {'eta': 0.10340081330363342, 'max_depth': 7, 'min_child_weight': 15, 'subsample': 0.6533291673867245, 'colsample_bytree': 0.929785762625, 'gamma': 1.4776078069288898, 'lambda': 9.27580258444157, 'alpha': 0.9428564250784821, 'num_boost_round': 600}. Best is trial 13 with value: 0.43283331467592073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:56:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 22. Best value: 0.444507:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [26:50<33:04, 73.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:57:50,808] Trial 22 finished with value: 0.44450653850452665 and parameters: {'eta': 0.20305532176595223, 'max_depth': 8, 'min_child_weight': 17, 'subsample': 0.6074425029850297, 'colsample_bytree': 0.8268822028822889, 'gamma': 0.9968846331283965, 'lambda': 0.012562012050778977, 'alpha': 0.9517182997033248, 'num_boost_round': 500}. Best is trial 22 with value: 0.44450653850452665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:57:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 23. Best value: 0.446447:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [27:51<30:17, 69.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:58:52,270] Trial 23 finished with value: 0.44644650228718064 and parameters: {'eta': 0.2103804410553803, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.6042263814161108, 'colsample_bytree': 0.8379584556161299, 'gamma': 0.6894195135928064, 'lambda': 0.012001765450301594, 'alpha': 0.23041162967038759, 'num_boost_round': 400}. Best is trial 23 with value: 0.44644650228718064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [12:58:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 23. Best value: 0.446447:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [28:53<28:04, 67.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 12:59:53,755] Trial 24 finished with value: 0.4342920971795588 and parameters: {'eta': 0.1381787315572436, 'max_depth': 8, 'min_child_weight': 15, 'subsample': 0.6201534830523364, 'colsample_bytree': 0.8272773376318108, 'gamma': 1.0675345657330064, 'lambda': 0.006310480637820436, 'alpha': 0.25203622182951346, 'num_boost_round': 400}. Best is trial 23 with value: 0.44644650228718064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:00:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 23. Best value: 0.446447:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [29:41<24:41, 61.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:00:42,264] Trial 25 finished with value: 0.42134078212290504 and parameters: {'eta': 0.14727533860134556, 'max_depth': 8, 'min_child_weight': 16, 'subsample': 0.6046049728739498, 'colsample_bytree': 0.7434408372179612, 'gamma': 0.8094972892832922, 'lambda': 0.0071889585321587264, 'alpha': 0.5283826990662592, 'num_boost_round': 300}. Best is trial 23 with value: 0.44644650228718064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:00:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 23. Best value: 0.446447:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [30:42<23:35, 61.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:01:43,380] Trial 26 finished with value: 0.43990398034946687 and parameters: {'eta': 0.21041870053144116, 'max_depth': 8, 'min_child_weight': 15, 'subsample': 0.6120713018226301, 'colsample_bytree': 0.8232459852588678, 'gamma': 0.025542478915377753, 'lambda': 0.011211373264882077, 'alpha': 0.011147742611755137, 'num_boost_round': 400}. Best is trial 23 with value: 0.44644650228718064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:01:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 23. Best value: 0.446447:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [32:03<24:42, 67.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:03:04,489] Trial 27 finished with value: 0.4389172965762561 and parameters: {'eta': 0.2078342399266211, 'max_depth': 8, 'min_child_weight': 18, 'subsample': 0.6018242527644581, 'colsample_bytree': 0.7012947967061594, 'gamma': 0.06846754505654183, 'lambda': 0.03956910238656795, 'alpha': 0.01911525464716762, 'num_boost_round': 700}. Best is trial 23 with value: 0.44644650228718064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:03:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 23. Best value: 0.446447:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [33:04<22:54, 65.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:04:05,445] Trial 28 finished with value: 0.4377792672028597 and parameters: {'eta': 0.20469826412877434, 'max_depth': 8, 'min_child_weight': 15, 'subsample': 0.6416899297407693, 'colsample_bytree': 0.8105863783411896, 'gamma': 0.2581667522976163, 'lambda': 6.764969218219065e-05, 'alpha': 0.0015815447182384568, 'num_boost_round': 400}. Best is trial 23 with value: 0.44644650228718064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:04:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 29. Best value: 0.456293:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [35:42<31:03, 93.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:06:43,278] Trial 29 finished with value: 0.45629331544824503 and parameters: {'eta': 0.2119913143426212, 'max_depth': 8, 'min_child_weight': 20, 'subsample': 0.6830709286506377, 'colsample_bytree': 0.7555971552751897, 'gamma': 0.005464206831312372, 'lambda': 9.937903090998755e-06, 'alpha': 0.029987385801414235, 'num_boost_round': 1500}. Best is trial 29 with value: 0.45629331544824503.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:06:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 29. Best value: 0.456293:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [37:39<31:42, 100.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:08:39,632] Trial 30 finished with value: 0.39883779404369446 and parameters: {'eta': 0.06464847198539596, 'max_depth': 6, 'min_child_weight': 19, 'subsample': 0.6883715253924405, 'colsample_bytree': 0.6856792222379116, 'gamma': 0.7901338820086434, 'lambda': 2.947970132253066e-06, 'alpha': 2.592459841108678, 'num_boost_round': 1500}. Best is trial 29 with value: 0.45629331544824503.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:08:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 29. Best value: 0.456293:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [39:16<29:47, 99.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:10:17,076] Trial 31 finished with value: 0.4502417069511585 and parameters: {'eta': 0.20077916460214343, 'max_depth': 8, 'min_child_weight': 19, 'subsample': 0.6515129179390527, 'colsample_bytree': 0.7560348852804613, 'gamma': 0.6726709844646308, 'lambda': 1.7351872590228793e-05, 'alpha': 0.007055891259721372, 'num_boost_round': 1400}. Best is trial 29 with value: 0.45629331544824503.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:10:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 32. Best value: 0.460573:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [41:41<32:00, 112.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-31 13:12:41,855] Trial 32 finished with value: 0.46057327682355564 and parameters: {'eta': 0.16294447195189452, 'max_depth': 8, 'min_child_weight': 20, 'subsample': 0.6484825388288731, 'colsample_bytree': 0.7708348393224855, 'gamma': 0.7165007134041275, 'lambda': 7.5440807588555035e-06, 'alpha': 0.062420940263057806, 'num_boost_round': 1400}. Best is trial 32 with value: 0.46057327682355564.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [13:12:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"single_precision_histogram\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "Best trial: 32. Best value: 0.460573:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [42:54<22:06, 78.01s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-07-31 13:13:54,838] Trial 33 failed with parameters: {'eta': 0.1683192252772687, 'max_depth': 8, 'min_child_weight': 20, 'subsample': 0.650877028538525, 'colsample_bytree': 0.7636606745146671, 'gamma': 0.4982249771945027, 'lambda': 1.715039819604432e-05, 'alpha': 0.036004453144688475, 'num_boost_round': 1400} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\1tiii\\AppData\\Local\\Temp\\ipykernel_12180\\2573677029.py\", line 3, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, data[:n2]), n_trials=50, show_progress_bar=True, gc_after_trial=True)\n",
      "                                 ~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\1tiii\\AppData\\Local\\Temp\\ipykernel_12180\\1600262994.py\", line 123, in objective\n",
      "    hit_at_3 = train_single_split(\n",
      "        data_xgb=data_xgb,\n",
      "    ...<2 lines>...\n",
      "        seed=42,\n",
      "    )\n",
      "  File \"C:\\Users\\1tiii\\AppData\\Local\\Temp\\ipykernel_12180\\1600262994.py\", line 56, in train_single_split\n",
      "    bst = xgb.train(\n",
      "        params,\n",
      "    ...<4 lines>...\n",
      "        verbose_eval=False,\n",
      "    )\n",
      "  File \"d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\training.py\", line 183, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 2247, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self.handle, ctypes.c_int(iteration), dtrain.handle\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-31 13:13:54,852] Trial 33 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      2\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 3) Report best params & save\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest hit@3:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(study.best_value, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      2\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m study.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, n_trials=\u001b[32m50\u001b[39m, show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m, gc_after_trial=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 3) Report best params & save\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest hit@3:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(study.best_value, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, data)\u001b[39m\n\u001b[32m    115\u001b[39m num_boost_round = trial.suggest_int(\u001b[33m\"\u001b[39m\u001b[33mnum_boost_round\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m300\u001b[39m, \u001b[32m1500\u001b[39m, step=\u001b[32m100\u001b[39m)\n\u001b[32m    116\u001b[39m data_xgb = data.with_columns([\n\u001b[32m    117\u001b[39m (pl.col(c).rank(\u001b[33m\"\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m\"\u001b[39m) - \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# rank starts at 1 ‚Üí shift to 0\u001b[39;00m\n\u001b[32m    118\u001b[39m .fill_null(-\u001b[32m1\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m CAT_FEATURES_FINAL\n\u001b[32m    122\u001b[39m ])\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m hit_at_3 = \u001b[43mtrain_single_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_xgb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_xgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hit_at_3\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mtrain_single_split\u001b[39m\u001b[34m(data_xgb, params, num_boost_round, seed)\u001b[39m\n\u001b[32m     42\u001b[39m dtrain = xgb.DMatrix(\n\u001b[32m     43\u001b[39m     train_df.select(feature_cols).to_numpy(),\n\u001b[32m     44\u001b[39m     label=train_df.select(LABEL_COL).to_numpy().ravel(),\n\u001b[32m     45\u001b[39m     group=get_group_sizes(train_df.select(GROUP_COL).to_numpy().ravel()),\n\u001b[32m     46\u001b[39m     feature_names=feature_cols,\n\u001b[32m     47\u001b[39m )\n\u001b[32m     49\u001b[39m dval = xgb.DMatrix(\n\u001b[32m     50\u001b[39m     val_df.select(feature_cols).to_numpy(),\n\u001b[32m     51\u001b[39m     label=val_df.select(LABEL_COL).to_numpy().ravel(),\n\u001b[32m     52\u001b[39m     group=get_group_sizes(val_df.select(GROUP_COL).to_numpy().ravel()),\n\u001b[32m     53\u001b[39m     feature_names=feature_cols,\n\u001b[32m     54\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m bst = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# NDCG@3 produced by XGBoost is geometric mean across groups; for hit@3 we compute manually\u001b[39;00m\n\u001b[32m     66\u001b[39m preds = bst.predict(dval)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda trial: objective(trial, data[:n2]), n_trials=50, show_progress_bar=True, gc_after_trial=True)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Report best params & save\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\nBest hit@3:\", round(study.best_value, 4))\n",
    "print(\"Best params:\\n\", study.best_params)\n",
    "\n",
    "out_dir = Path(\"optuna_results\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "(out_dir / \"best_params.json\").write_text(study.best_trial.params.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360adfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.16294447195189452,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 20,\n",
       " 'subsample': 0.6484825388288731,\n",
       " 'colsample_bytree': 0.7708348393224855,\n",
       " 'gamma': 0.7165007134041275,\n",
       " 'lambda': 7.5440807588555035e-06,\n",
       " 'alpha': 0.062420940263057806,\n",
       " 'num_boost_round': 1400}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47dc4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1) Train / evaluate on a subset of columns\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def train_single_split_subset(\n",
    "    data_xgb: pl.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    params: dict,\n",
    "    num_boost_round: int,\n",
    "    seed: int = 42,\n",
    ") -> float:\n",
    "    \"\"\"Return hit@3 on an 80/20 group‚Äëbased split using only feature_cols.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    groups_unique = data_xgb.select(GROUP_COL).unique().to_numpy().ravel()\n",
    "    val_groups = rng.choice(\n",
    "        groups_unique, size=max(1, int(0.2 * len(groups_unique))), replace=False\n",
    "    )\n",
    "\n",
    "    val_df   = data_xgb.filter(pl.col(GROUP_COL).is_in(val_groups))\n",
    "    train_df = data_xgb.filter(~pl.col(GROUP_COL).is_in(val_groups))\n",
    "\n",
    "    dtrain = xgb.DMatrix(\n",
    "        train_df.select(feature_cols).to_numpy(),\n",
    "        label=train_df.select(LABEL_COL).to_numpy().ravel(),\n",
    "        group=get_group_sizes(train_df.select(GROUP_COL).to_numpy().ravel()),\n",
    "        feature_names=feature_cols,\n",
    "    )\n",
    "    dval = xgb.DMatrix(\n",
    "        val_df.select(feature_cols).to_numpy(),\n",
    "        label=val_df.select(LABEL_COL).to_numpy().ravel(),\n",
    "        group=get_group_sizes(val_df.select(GROUP_COL).to_numpy().ravel()),\n",
    "        feature_names=feature_cols,\n",
    "    )\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dval, \"val\")],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # --- hit@3 -----------------------------------------------------------\n",
    "    preds       = bst.predict(dval)\n",
    "    ranker_ids  = val_df.select(GROUP_COL).to_numpy().ravel()\n",
    "    labels      = dval.get_label()\n",
    "\n",
    "    order = np.argsort(ranker_ids, kind=\"stable\")\n",
    "    ranker_ids, labels, preds = ranker_ids[order], labels[order], preds[order]\n",
    "\n",
    "    hit_total = group_total = 0\n",
    "    i = 0\n",
    "    while i < len(ranker_ids):\n",
    "        g = ranker_ids[i]\n",
    "        j = i\n",
    "        while j < len(ranker_ids) and ranker_ids[j] == g:\n",
    "            j += 1\n",
    "        if (j - i) > 10:                       # skip tiny groups\n",
    "            top3 = np.argsort(preds[i:j])[::-1][:3]\n",
    "            hit_total += int(labels[i:j][top3].sum() > 0)\n",
    "            group_total += 1\n",
    "        i = j\n",
    "    return hit_total / group_total if group_total else 0.0\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2) Greedy step‚Äëforward selection\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def step_forward_selection(\n",
    "    data_xgb: pl.DataFrame,\n",
    "    all_features: List[str],\n",
    "    params: dict,\n",
    "    num_boost_round: int,\n",
    "    seed: int = 42,\n",
    "    min_improvement: float = 1e-4,\n",
    ") -> Tuple[List[str], float]:\n",
    "    \"\"\"\n",
    "    Greedy SFS: start with empty set, add best column each round.\n",
    "    Stops when no remaining feature improves hit@3 by > min_improvement.\n",
    "    Returns (selected_features, best_score).\n",
    "    \"\"\"\n",
    "    remaining = set(all_features)\n",
    "    selected: List[str] = []\n",
    "    best_score = 0.0\n",
    "\n",
    "    while remaining:\n",
    "        trial_scores = {}\n",
    "        for feat in remaining:\n",
    "            score = train_single_split_subset(\n",
    "                data_xgb,\n",
    "                selected + [feat],\n",
    "                deepcopy(params),          # XGBoost mutates dict ‚Üí copy!\n",
    "                num_boost_round,\n",
    "                seed,\n",
    "            )\n",
    "            trial_scores[feat] = score\n",
    "            \n",
    "        # pick the feature with the highest score\n",
    "        feat_best, score_best = max(trial_scores.items(), key=lambda kv: kv[1])\n",
    "\n",
    "        # check if it is a real improvement\n",
    "        if score_best - best_score < min_improvement:\n",
    "            print(f\"Stopping: no feature improves hit@3 by ‚â•{min_improvement:.1e}\")\n",
    "            break\n",
    "\n",
    "        selected.append(feat_best)\n",
    "        remaining.remove(feat_best)\n",
    "        best_score = score_best\n",
    "        print(f\"Added {feat_best:>30}  ‚Üí  hit@3 = {best_score:.4f}\")\n",
    "\n",
    "    return selected, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150fece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"objective\":   \"rank:pairwise\",\n",
    "\"eval_metric\": \"ndcg@3\",\n",
    "\"tree_method\": \"hist\",      # üî• much faster\n",
    "\"seed\":        42,\n",
    "\"n_jobs\":      -1,\n",
    "'eta': 0.11258528754406343,\n",
    " 'max_depth': 7,\n",
    " 'min_child_weight': 9,\n",
    " 'subsample': 0.6386911919274852,\n",
    " 'colsample_bytree': 0.8167665572930206,\n",
    " 'gamma': 3.3978723412953182,\n",
    " 'lambda': 0.0015573270572558455,\n",
    " 'alpha': 0.0007046464277948389,\n",
    " 'device': 'cuda'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef3dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added               opt_ticket_score  ‚Üí  hit@3 = 0.5022\n",
      "Added      miniRules1_monetaryAmount  ‚Üí  hit@3 = 0.5263\n",
      "Added               avg_oneway_price  ‚Üí  hit@3 = 0.5383\n",
      "Added                      log_price  ‚Üí  hit@3 = 0.5562\n",
      "Added                   company_freq  ‚Üí  hit@3 = 0.5749\n",
      "Added       legs0_departureAt_period  ‚Üí  hit@3 = 0.5813\n",
      "Added       legs1_departureAt_period  ‚Üí  hit@3 = 0.5962\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m data_ready = data.with_columns([\n\u001b[32m      2\u001b[39m (pl.col(c).rank(\u001b[33m\"\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m\"\u001b[39m) - \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# rank starts at 1 ‚Üí shift to 0\u001b[39;00m\n\u001b[32m      3\u001b[39m .fill_null(-\u001b[32m1\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cat_features_final\n\u001b[32m      7\u001b[39m ])\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m chosen_feats, final_hit3 = \u001b[43mstep_forward_selection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m     \u001b[49m\u001b[43mdata_xgb\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m     \u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m     \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m     \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m  \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m     \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 96\u001b[39m, in \u001b[36mstep_forward_selection\u001b[39m\u001b[34m(data_xgb, all_features, params, num_boost_round, seed, min_improvement)\u001b[39m\n\u001b[32m     94\u001b[39m trial_scores = {}\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m remaining:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     score = \u001b[43mtrain_single_split_subset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_xgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mselected\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# XGBoost mutates dict ‚Üí copy!\u001b[39;49;00m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     trial_scores[feat] = score\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# pick the feature with the highest score\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mtrain_single_split_subset\u001b[39m\u001b[34m(data_xgb, feature_cols, params, num_boost_round, seed)\u001b[39m\n\u001b[32m     28\u001b[39m dtrain = xgb.DMatrix(\n\u001b[32m     29\u001b[39m     train_df.select(feature_cols).to_numpy(),\n\u001b[32m     30\u001b[39m     label=train_df.select(LABEL_COL).to_numpy().ravel(),\n\u001b[32m     31\u001b[39m     group=get_group_sizes(train_df.select(GROUP_COL).to_numpy().ravel()),\n\u001b[32m     32\u001b[39m     feature_names=feature_cols,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m dval = xgb.DMatrix(\n\u001b[32m     35\u001b[39m     val_df.select(feature_cols).to_numpy(),\n\u001b[32m     36\u001b[39m     label=val_df.select(LABEL_COL).to_numpy().ravel(),\n\u001b[32m     37\u001b[39m     group=get_group_sizes(val_df.select(GROUP_COL).to_numpy().ravel()),\n\u001b[32m     38\u001b[39m     feature_names=feature_cols,\n\u001b[32m     39\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m bst = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# --- hit@3 -----------------------------------------------------------\u001b[39;00m\n\u001b[32m     51\u001b[39m preds       = bst.predict(dval)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\training.py:184\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    183\u001b[39m     bst.update(dtrain, iteration=i, fobj=obj)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    187\u001b[39m bst = cb_container.after_training(bst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\callback.py:264\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m name.find(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m) == -\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDataset name should not contain `-`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m score: \u001b[38;5;28mstr\u001b[39m = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\FlightRank 2025 Aeroclub RecSys Cup\\.venv\\Lib\\site-packages\\xgboost\\core.py:2353\u001b[39m, in \u001b[36mBooster.eval_set\u001b[39m\u001b[34m(self, evals, iteration, feval, output_margin)\u001b[39m\n\u001b[32m   2350\u001b[39m evnames = c_array(ctypes.c_char_p, [c_str(d[\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[32m   2351\u001b[39m msg = ctypes.c_char_p()\n\u001b[32m   2352\u001b[39m _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2353\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2360\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2361\u001b[39m )\n\u001b[32m   2362\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m msg.value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2363\u001b[39m res = msg.value.decode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data_ready = data.with_columns([\n",
    "(pl.col(c).rank(\"dense\") - 1)  # rank starts at 1 ‚Üí shift to 0\n",
    ".fill_null(-1)\n",
    ".cast(pl.Int32)\n",
    ".alias(c)\n",
    "for c in cat_features_final\n",
    "])\n",
    "chosen_feats, final_hit3 = step_forward_selection(\n",
    "     data_xgb         = data_ready,\n",
    "     all_features     = feature_list,\n",
    "     params           = params,\n",
    "     num_boost_round  = 1000,\n",
    "     seed             = 42,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20cb576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
